{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204312e2-f466-469a-8e76-d45e291baf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from typing import Tuple, Optional, List, cast\n",
    "from logging import getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "INPUT_WIDTH: int = 640\n",
    "INPUT_HEIGHT: int = 640\n",
    "\n",
    "def _reorder_cv_image(src_image: np.ndarray) -> np.ndarray:\n",
    "    assert src_image.ndim == 3\n",
    "    assert src_image.shape[2] == 3 or src_image.shape[2] == 4\n",
    "    dst_image: np.ndarray = src_image.copy()\n",
    "    if dst_image.shape[2] == 3:\n",
    "        dst_image = cv2.cvtColor(dst_image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        dst_image = cv2.cvtColor(dst_image, cv2.COLOR_BGRA2RGB)\n",
    "    return dst_image\n",
    "\n",
    "def _resize_input_image(\n",
    "    image: np.ndarray, pad_value: Tuple[int, int, int] = (114, 114, 114)) -> np.ndarray:\n",
    "\n",
    "    h, w, c = image.shape\n",
    "    ratio_width: float = float(INPUT_WIDTH) / float(w)\n",
    "    ratio_height: float = float(INPUT_HEIGHT) / float(h)\n",
    "\n",
    "    ratio: float = 1.0\n",
    "    dst_width: int = INPUT_WIDTH\n",
    "    dst_height: int = INPUT_HEIGHT\n",
    "    pad_width: int = 0\n",
    "    pad_height: int = 0\n",
    "    if ratio_width < ratio_height:\n",
    "        # Letter box\n",
    "        ratio = ratio_width\n",
    "        dst_width = INPUT_WIDTH\n",
    "        dst_height = min(round(h * ratio), INPUT_HEIGHT)\n",
    "        pad_height = INPUT_HEIGHT - dst_height\n",
    "    else:\n",
    "        # Pillar box\n",
    "        ratio = ratio_height\n",
    "        dst_width = min(round(w * ratio), INPUT_WIDTH)\n",
    "        dst_height = INPUT_HEIGHT\n",
    "        pad_width = INPUT_WIDTH - dst_width\n",
    "    pad_top: int = pad_height // 2\n",
    "    pad_bottom: int = pad_height - pad_top\n",
    "    pad_left: int = pad_width // 2\n",
    "    pad_right: int = pad_width - pad_left\n",
    "\n",
    "    logger.debug('{} {} {} {} {} {}'.format(\n",
    "        dst_width, dst_height, pad_top, pad_bottom, pad_left, pad_right\n",
    "    ))\n",
    "    \n",
    "    # Resize\n",
    "    rescaled_image: np.ndarray = cv2.resize(\n",
    "        src=image, dsize=(dst_width, dst_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Pad\n",
    "    padded_image: np.ndarray = cv2.copyMakeBorder(src=rescaled_image, \n",
    "        top=pad_top, bottom=pad_bottom, left=pad_left, right=pad_right, \n",
    "        borderType=cv2.BORDER_CONSTANT, value=pad_value)\n",
    "\n",
    "    # Debug\n",
    "    # cv2.imwrite('padded_image.png', padded_image)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def _preprocess_images(images: List[np.ndarray]) -> np.ndarray:\n",
    "    cv_images: List[np.ndarray] = [_resize_input_image(img) for img in images]\n",
    "    np_images: List[np.ndarray] = [\n",
    "        np.ascontiguousarray(img.transpose(2, 0, 1), dtype='uint8') for img in cv_images\n",
    "    ]\n",
    "    return np.array(np_images)\n",
    "\n",
    "def preprocess_cv_images(images: List[np.ndarray]) -> np.ndarray:\n",
    "    cv_images: List[np.ndarray] = [_reorder_cv_image(img) for img in images]\n",
    "    return _preprocess_images(cv_images).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8af3ef5f-1fd5-4640-89ed-1f26929072c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from attrdict import AttrDict\n",
    "\n",
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import InferenceServerException\n",
    "import tritonclient.grpc.model_config_pb2 as mc\n",
    "\n",
    "class TritonClientError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TritonClient():\n",
    "\n",
    "    def __init__(self, url='localhost:8000'):\n",
    "        self.request = None\n",
    "        self.response = None\n",
    "\n",
    "        try:\n",
    "            self.client = httpclient.InferenceServerClient(\n",
    "                url=url, verbose=False, concurrency=1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print('could not create client: {}'.format(e))\n",
    "            raise TritonClientError(str(e))\n",
    "\n",
    "    def infer(self, image, class_count=0):\n",
    "        # if self.max_batch_size > 0:\n",
    "        #     image = image[np.newaxis, :]\n",
    "\n",
    "        inputs = [httpclient.InferInput(\"image\", (1,3,640,640), \"FP32\"), httpclient.InferInput(\"scale_factor\", (1,2), \"FP32\")]\n",
    "        inputs[0].set_data_from_numpy(image)\n",
    "        inputs[1].set_data_from_numpy(np.array([[1.0, 1.0]]).astype(np.float32))\n",
    "\n",
    "        outputs = [httpclient.InferRequestedOutput(\"multiclass_nms3_0.tmp_0\", class_count=class_count)]\n",
    "\n",
    "        try:\n",
    "            self.request = self.client.async_infer(\n",
    "                \"ppyoloe_detection\", inputs, request_id='0',\n",
    "                model_version=\"1\", outputs=outputs\n",
    "            )\n",
    "        except InferenceServerException as e:\n",
    "            print('Inference failed: {}'.format(e))\n",
    "            raise TritonClientError(str(e))\n",
    "\n",
    "    def get_results(self):\n",
    "        if self.request is None:\n",
    "            return None\n",
    "\n",
    "        self.response = self.request.get_result()\n",
    "        output_array = self.response.as_numpy(\"multiclass_nms3_0.tmp_0\")\n",
    "\n",
    "        return output_array\n",
    "\n",
    "class TritonClient_2():\n",
    "\n",
    "    def __init__(self, url='localhost:8000'):\n",
    "        self.request = None\n",
    "        self.response = None\n",
    "\n",
    "        try:\n",
    "            self.client = httpclient.InferenceServerClient(\n",
    "                url=url, verbose=False, concurrency=1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print('could not create client: {}'.format(e))\n",
    "            raise TritonClientError(str(e))\n",
    "\n",
    "    def infer(self, image, class_count=0, car_count=-1):\n",
    "        # if self.max_batch_size > 0:\n",
    "        #     image = image[np.newaxis, :]\n",
    "\n",
    "        inputs = [httpclient.InferInput(\"x\", (car_count,3,192,256), \"FP32\")]\n",
    "        inputs[0].set_data_from_numpy(image)\n",
    "\n",
    "        outputs = [httpclient.InferRequestedOutput(\"sigmoid_2.tmp_0\", class_count=class_count)]\n",
    "\n",
    "        try:\n",
    "            self.request = self.client.async_infer(\n",
    "                \"pp_attribute\", inputs, request_id='0',\n",
    "                model_version=\"1\", outputs=outputs\n",
    "            )\n",
    "        except InferenceServerException as e:\n",
    "            print('Inference failed: {}'.format(e))\n",
    "            raise TritonClientError(str(e))\n",
    "\n",
    "    def get_results(self):\n",
    "        if self.request is None:\n",
    "            return None\n",
    "\n",
    "        self.response = self.request.get_result()\n",
    "        output_array = self.response.as_numpy(\"sigmoid_2.tmp_0\")\n",
    "\n",
    "        return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cc50792-1969-4bd0-9343-a93127864c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import contextlib\n",
    "\n",
    "from tritonclient.http import InferenceServerClient\n",
    "\n",
    "# Define image https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver\n",
    "# tag = 'nvcr.io/nvidia/tritonserver:21.10-py3'  # 6.4 GB\n",
    "\n",
    "# Pull the image\n",
    "# subprocess.call(f'docker pull {tag}', shell=True)\n",
    "\n",
    "# Run the Triton server and capture the container ID\n",
    "container_id = subprocess.check_output(\n",
    "    f'docker run -d --runtime=nvidia --gpus all --rm -v /home/user/ml/tmp/triton_repo:/models -p 8000:8000 nvcr.io/nvidia/tritonserver:22.12-py3 tritonserver --model-repository=/models',\n",
    "    shell=True).decode('utf-8').strip()\n",
    "\n",
    "# Wait for the Triton server to start\n",
    "triton_client = InferenceServerClient(url='localhost:8000', verbose=False, ssl=False)\n",
    "\n",
    "# Wait until model is ready\n",
    "for _ in range(10):\n",
    "    with contextlib.suppress(Exception):\n",
    "        assert triton_client.is_model_ready(model_name)\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d515480d-502d-47de-a7c3-68cc3fb18d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"4.png\")\n",
    "# blob = cv2.dnn.blobFromImage(im, 1 / 255.0, (640, 640), swapRB=True, crop=False)\n",
    "im = preprocess_cv_images([im])\n",
    "tr = TritonClient()\n",
    "tr.infer(im)\n",
    "results_list = tr.get_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776adead-f009-46a3-9c8d-419833f9c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_list.shape)\n",
    "print(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d67e5641-4584-45af-91ba-0d04e5f84841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805 1205\n"
     ]
    }
   ],
   "source": [
    "im = cv2.imread(\"4.png\")\n",
    "im_copy = cv2.imread(\"4.png\")\n",
    "\n",
    "height, width, _ = im.shape\n",
    "height_border = width - height if width >= height else 0\n",
    "width_border = height - width if height >= width else 0\n",
    "print(height, width)\n",
    "\n",
    "color_blue = (255,0,0)\n",
    "color_yellow = (0,255,255)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.7\n",
    "thickness_bbox = 1\n",
    "thickness_font = 2\n",
    "\n",
    "img_list = []\n",
    "points_list = []\n",
    "\n",
    "for res in results_list:\n",
    "    if res[1] > 0.5:\n",
    "        start_point = (int(res[2] / 640.0 * (width + width_border) - width_border // 2), int(res[3] / 640.0 * (height + height_border) - height_border // 2)) \n",
    "        end_point = (int(res[4] / 640.0 * (width + width_border) - width_border // 2), int(res[5] / 640.0 * (height + height_border) - height_border // 2))\n",
    "        # print(start_point, end_point)\n",
    "        im = cv2.rectangle(im, start_point, end_point, color_blue, thickness_bbox)\n",
    "        img_list.append(im_copy[max(start_point[1], 0):min(end_point[1], im.shape[0]), max(start_point[0],0):min(end_point[0],im.shape[1])])\n",
    "        points_list.append((max(start_point[0],0), max(start_point[1], 0)))\n",
    "\n",
    "INPUT_WIDTH = 256\n",
    "INPUT_HEIGHT = 192\n",
    "\n",
    "# for i, img in enumerate(img_list):\n",
    "#     cv2.imwrite(str(i)+\"_test.png\", img)\n",
    "\n",
    "# two type of solutions\n",
    "# img_list = np.divide(preprocess_cv_images(img_list), 255.0)\n",
    "img_list = np.array([(cv2.dnn.blobFromImage(i, 1.0/255.0, (256, 192), swapRB=True, crop=False))[0] for i in img_list])\n",
    "\n",
    "tr_2 = TritonClient_2()\n",
    "tr_2.infer(img_list, car_count=img_list.shape[0])\n",
    "results_list_2 = tr_2.get_results()\n",
    "\n",
    "index_to_name = [\"yellow\",\"orange\",\"green\",\"gray\",\"red\",\"blue\",\"white\",\"golden\",\"brown\",\"black\"]\n",
    "for i, res in enumerate(results_list_2):\n",
    "    elems = heapq.nlargest(2, (res[:10]).tolist())\n",
    "    indexes = [(res[:10]).tolist().index(elem) for elem in elems]\n",
    "    names = [index_to_name[index] for index in indexes]\n",
    "    im = cv2.putText(im, \" \".join(names), points_list[i], font, font_scale, color_yellow, thickness_font)\n",
    "\n",
    "cv2.imwrite(\"test.png\", im)\n",
    "\n",
    "INPUT_WIDTH = 640\n",
    "INPUT_HEIGHT = 640\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1dfe124f-96ec-4461-b21e-9a80a6036204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 19)\n",
      "['white', 'yellow']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['golden', 'yellow']\n",
      "[0.14636141, 0, 0, 0, 0, 0, 0, 0.28150034, 0, 0]\n",
      "['yellow', 'golden']\n",
      "[0.68341696, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['yellow', 'golden']\n",
      "[0.54350626, 0, 0, 0, 0, 0, 0, 0.47537476, 0, 0]\n",
      "['yellow', 'gray']\n",
      "[0.31309724, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['yellow', 'orange']\n",
      "[0.7011129, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['yellow', 'orange']\n",
      "[0.81452334, 0.12394434, 0, 0, 0, 0, 0, 0, 0.114370644, 0]\n",
      "['yellow', 'black']\n",
      "[0.86920476, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['yellow', 'golden']\n",
      "[0.79197735, 0, 0, 0, 0, 0, 0, 0.18329674, 0, 0]\n",
      "['yellow', 'golden']\n",
      "[0.8210252, 0, 0, 0, 0, 0, 0, 0.20357937, 0, 0.11740911]\n",
      "['yellow', 'golden']\n",
      "[0.77102125, 0, 0, 0, 0, 0, 0, 0.10154492, 0, 0]\n",
      "['yellow', 'golden']\n",
      "[0.5720386, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['yellow', 'black']\n",
      "[0.6041221, 0, 0, 0, 0, 0.13840717, 0, 0, 0.15746295, 0.2595371]\n",
      "['yellow', 'golden']\n",
      "[0.8444535, 0, 0, 0, 0, 0, 0, 0.33770996, 0, 0]\n",
      "['yellow', 'brown']\n",
      "[0.64375836, 0, 0, 0.17898262, 0, 0, 0, 0, 0.22580445, 0.17728162]\n",
      "['gray', 'golden']\n",
      "[0.19381368, 0, 0, 0.21300852, 0, 0, 0, 0.21148002, 0, 0]\n",
      "['yellow', 'black']\n",
      "[0.47712147, 0, 0, 0, 0, 0.21868789, 0.11983174, 0, 0.1185022, 0.2572788]\n",
      "['yellow', 'black']\n",
      "[0.5443401, 0, 0, 0, 0, 0.17473668, 0, 0, 0.10388535, 0.24722016]\n",
      "['yellow', 'black']\n",
      "[0.5276763, 0, 0, 0.100028515, 0, 0.15695179, 0, 0, 0, 0.25175548]\n",
      "['yellow', 'golden']\n",
      "[0.39711815, 0, 0, 0, 0, 0, 0, 0.384565, 0.13270456, 0.11564618]\n",
      "['yellow', 'black']\n",
      "[0.582488, 0.117069304, 0, 0.1543082, 0, 0, 0, 0.17181802, 0.15570831, 0.22530043]\n",
      "['yellow', 'orange']\n",
      "[0.7417795, 0.19923317, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['yellow', 'gray']\n",
      "[0.6537843, 0, 0, 0.12497145, 0, 0, 0, 0, 0, 0]\n",
      "['yellow', 'gray']\n",
      "[0.94969517, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['yellow', 'black']\n",
      "[0.5668559, 0.12191194, 0, 0, 0.12326485, 0, 0, 0, 0.13029766, 0.28836542]\n",
      "['yellow', 'black']\n",
      "[0.5689235, 0, 0, 0, 0, 0.15849614, 0, 0, 0.13586009, 0.26230437]\n",
      "['yellow', 'orange']\n",
      "[0.6110865, 0.18996996, 0, 0.12319684, 0, 0, 0, 0.124301374, 0.15985292, 0.1683281]\n",
      "['yellow', 'black']\n",
      "[0.3987252, 0, 0, 0, 0, 0.24036044, 0.12404817, 0, 0, 0.25937212]\n",
      "['yellow', 'golden']\n",
      "[0.380121, 0, 0, 0, 0, 0, 0, 0.37843436, 0, 0.11354977]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "print(results_list_2.shape)\n",
    "index_to_name = [\"yellow\",\"orange\",\"green\",\"gray\",\"red\",\"blue\",\"white\",\"golden\",\"brown\",\"black\"]\n",
    "for res in results_list_2:\n",
    "    elems = heapq.nlargest(2, (res[:10]).tolist())\n",
    "    indexes = [(res[:10]).tolist().index(elem) for elem in elems]\n",
    "    print([index_to_name[index] for index in indexes])\n",
    "    print([res[i] if res[i] > 0.1 else 0 for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "132d673d-be82-4ea6-9c4c-23367fa60023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206de1c24cf3054803f8cbc89f1b0de94b60237971c338e9bef7d24287739151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(f'docker kill {container_id}', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1f956-8cbb-4718-9550-b68033844696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d751b-a768-4b67-9b8d-e3623ee77e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
